{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features and labels\n",
    "features = np.load('features.npy')\n",
    "labels = np.load('labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5334\n",
      "Shape of one feature: (40, 115)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(features))\n",
    "print(\"Shape of one feature:\", features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4267, 40, 115)\n",
      "(1067, 40, 115)\n",
      "(4267,)\n",
      "(1067,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 115)\n",
      "(40, 115)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Stack all training features to compute mean and std\n",
    "all_train_features = np.stack(X_train, axis=0)  # Shape: (num_samples, n_mfcc, max_length)\n",
    "\n",
    "# Compute mean and std across the dataset (axis=0)\n",
    "mean = np.mean(all_train_features, axis=0)\n",
    "std = np.std(all_train_features, axis=0)\n",
    "\n",
    "print(mean.shape)\n",
    "print(std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features, mean, std):\n",
    "    return (features - mean) / std\n",
    "\n",
    "# Normalize training data\n",
    "X_train_norm = [normalize(f, mean, std) for f in X_train]\n",
    "\n",
    "# Normalize validation data\n",
    "X_val_norm = [normalize(f, mean, std) for f in X_val]\n",
    "\n",
    "\n",
    "np.save('mean.npy', mean)\n",
    "np.save('std.npy', std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.X = features\n",
    "        self.y = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert features to tensor and add channel dimension\n",
    "        mfcc = self.X[idx]\n",
    "        mfcc = torch.tensor(mfcc, dtype=torch.float32)\n",
    "        mfcc = mfcc.unsqueeze(0)  # Add channel dimension,  Shape: (1, n_mfcc, max_length)\n",
    "        label = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return mfcc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = AudioDataset(X_train_norm, y_train)\n",
    "val_dataset = AudioDataset(X_val_norm, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_labels, input_height, input_width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3,3),\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=(3,3),\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        # Calculate the size after convolutional layers\n",
    "        def conv2d_output_size(size, kernel_size=3, stride=1, padding=1):\n",
    "            return (size + 2*padding - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        def maxpool_output_size(size, kernel_size=2, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        # Compute height and width after conv and pooling layers\n",
    "        h = input_height\n",
    "        w = input_width\n",
    "\n",
    "        h = conv2d_output_size(h)\n",
    "        h = maxpool_output_size(h)\n",
    "        h = conv2d_output_size(h)\n",
    "        h = maxpool_output_size(h)\n",
    "\n",
    "        w = conv2d_output_size(w)\n",
    "        w = maxpool_output_size(w)\n",
    "        w = conv2d_output_size(w)\n",
    "        w = maxpool_output_size(w)\n",
    "\n",
    "        # flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # linear\n",
    "        self.linear = nn.Linear(32*h*w, num_labels)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(np.unique(labels))\n",
    "n_mfcc= X_train_norm[0].shape[0]\n",
    "max_length = X_train_norm[0].shape[1]\n",
    "\n",
    "model = AudioCNN(num_labels, input_height=n_mfcc, input_width=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.4512\n",
      "Validation Loss: 0.1115, Validation Accuracy: 97.5633%\n",
      "Epoch 2/100, Loss: 0.0486\n",
      "Validation Loss: 0.0326, Validation Accuracy: 98.7816%\n",
      "Epoch 3/100, Loss: 0.0146\n",
      "Validation Loss: 0.0112, Validation Accuracy: 99.7188%\n",
      "Epoch 4/100, Loss: 0.0070\n",
      "Validation Loss: 0.0135, Validation Accuracy: 99.3440%\n",
      "Epoch 5/100, Loss: 0.0088\n",
      "Validation Loss: 0.0102, Validation Accuracy: 99.5314%\n",
      "Epoch 6/100, Loss: 0.0059\n",
      "Validation Loss: 0.0074, Validation Accuracy: 99.4377%\n",
      "Epoch 7/100, Loss: 0.0046\n",
      "Validation Loss: 0.0052, Validation Accuracy: 99.9063%\n",
      "Epoch 8/100, Loss: 0.0052\n",
      "Validation Loss: 0.0093, Validation Accuracy: 99.3440%\n",
      "Epoch 9/100, Loss: 0.0050\n",
      "Validation Loss: 0.0041, Validation Accuracy: 99.7188%\n",
      "Epoch 10/100, Loss: 0.0044\n",
      "Validation Loss: 0.0106, Validation Accuracy: 99.5314%\n",
      "Epoch 11/100, Loss: 0.0060\n",
      "Validation Loss: 0.0702, Validation Accuracy: 99.2502%\n",
      "Epoch 12/100, Loss: 0.1374\n",
      "Validation Loss: 0.5639, Validation Accuracy: 93.2521%\n",
      "Epoch 13/100, Loss: 0.2250\n",
      "Validation Loss: 0.2019, Validation Accuracy: 98.0319%\n",
      "Epoch 14/100, Loss: 0.0234\n",
      "Validation Loss: 0.0907, Validation Accuracy: 99.6251%\n",
      "Epoch 15/100, Loss: 0.0045\n",
      "Validation Loss: 0.1053, Validation Accuracy: 99.7188%\n",
      "Epoch 16/100, Loss: 0.0046\n",
      "Validation Loss: 0.1066, Validation Accuracy: 99.6251%\n",
      "Epoch 17/100, Loss: 0.0061\n",
      "Validation Loss: 0.0880, Validation Accuracy: 99.3440%\n",
      "Epoch 18/100, Loss: 0.0051\n",
      "Validation Loss: 0.0886, Validation Accuracy: 99.3440%\n",
      "Epoch 19/100, Loss: 0.0037\n",
      "Validation Loss: 0.0920, Validation Accuracy: 99.4377%\n",
      "Epoch 20/100, Loss: 0.0024\n",
      "Validation Loss: 0.0941, Validation Accuracy: 99.3440%\n",
      "Epoch 21/100, Loss: 0.0048\n",
      "Validation Loss: 0.0907, Validation Accuracy: 99.4377%\n",
      "Epoch 22/100, Loss: 0.0084\n",
      "Validation Loss: 0.0884, Validation Accuracy: 99.4377%\n",
      "Epoch 23/100, Loss: 0.0038\n",
      "Validation Loss: 0.0905, Validation Accuracy: 99.4377%\n",
      "Epoch 24/100, Loss: 0.0037\n",
      "Validation Loss: 0.0979, Validation Accuracy: 99.3440%\n",
      "Epoch 25/100, Loss: 0.0066\n",
      "Validation Loss: 0.0751, Validation Accuracy: 99.3440%\n",
      "Epoch 26/100, Loss: 0.0025\n",
      "Validation Loss: 0.0915, Validation Accuracy: 99.3440%\n",
      "Epoch 27/100, Loss: 0.0033\n",
      "Validation Loss: 0.0966, Validation Accuracy: 99.3440%\n",
      "Epoch 28/100, Loss: 0.0013\n",
      "Validation Loss: 0.0870, Validation Accuracy: 99.3440%\n",
      "Epoch 29/100, Loss: 0.0041\n",
      "Validation Loss: 0.0939, Validation Accuracy: 99.3440%\n",
      "Epoch 30/100, Loss: 0.0034\n",
      "Validation Loss: 0.1001, Validation Accuracy: 99.3440%\n",
      "Epoch 31/100, Loss: 0.0053\n",
      "Validation Loss: 0.1194, Validation Accuracy: 99.3440%\n",
      "Epoch 32/100, Loss: 0.0030\n",
      "Validation Loss: 0.1033, Validation Accuracy: 99.3440%\n",
      "Epoch 33/100, Loss: 0.0045\n",
      "Validation Loss: 0.0974, Validation Accuracy: 99.3440%\n",
      "Epoch 34/100, Loss: 0.0044\n",
      "Validation Loss: 0.1221, Validation Accuracy: 99.3440%\n",
      "Epoch 35/100, Loss: 0.0051\n",
      "Validation Loss: 0.0606, Validation Accuracy: 99.6251%\n",
      "Epoch 36/100, Loss: 0.0044\n",
      "Validation Loss: 0.1289, Validation Accuracy: 99.3440%\n",
      "Epoch 37/100, Loss: 0.0054\n",
      "Validation Loss: 0.0491, Validation Accuracy: 99.2502%\n",
      "Epoch 38/100, Loss: 0.1033\n",
      "Validation Loss: 0.4330, Validation Accuracy: 94.7516%\n",
      "Epoch 39/100, Loss: 0.1693\n",
      "Validation Loss: 0.1120, Validation Accuracy: 98.8754%\n",
      "Epoch 40/100, Loss: 0.0224\n",
      "Validation Loss: 0.0583, Validation Accuracy: 99.5314%\n",
      "Epoch 41/100, Loss: 0.0093\n",
      "Validation Loss: 0.0564, Validation Accuracy: 99.7188%\n",
      "Epoch 42/100, Loss: 0.0025\n",
      "Validation Loss: 0.0620, Validation Accuracy: 99.7188%\n",
      "Epoch 43/100, Loss: 0.0033\n",
      "Validation Loss: 0.0518, Validation Accuracy: 99.7188%\n",
      "Epoch 44/100, Loss: 0.0038\n",
      "Validation Loss: 0.0576, Validation Accuracy: 99.7188%\n",
      "Epoch 45/100, Loss: 0.0059\n",
      "Validation Loss: 0.0490, Validation Accuracy: 99.7188%\n",
      "Epoch 46/100, Loss: 0.0055\n",
      "Validation Loss: 0.0497, Validation Accuracy: 99.6251%\n",
      "Epoch 47/100, Loss: 0.0039\n",
      "Validation Loss: 0.0517, Validation Accuracy: 99.7188%\n",
      "Epoch 48/100, Loss: 0.0031\n",
      "Validation Loss: 0.0525, Validation Accuracy: 99.7188%\n",
      "Epoch 49/100, Loss: 0.0031\n",
      "Validation Loss: 0.0498, Validation Accuracy: 99.7188%\n",
      "Epoch 50/100, Loss: 0.0056\n",
      "Validation Loss: 0.0531, Validation Accuracy: 99.6251%\n",
      "Epoch 51/100, Loss: 0.0035\n",
      "Validation Loss: 0.0513, Validation Accuracy: 99.7188%\n",
      "Epoch 52/100, Loss: 0.0037\n",
      "Validation Loss: 0.0512, Validation Accuracy: 99.7188%\n",
      "Epoch 53/100, Loss: 0.0027\n",
      "Validation Loss: 0.0470, Validation Accuracy: 99.6251%\n",
      "Epoch 54/100, Loss: 0.0039\n",
      "Validation Loss: 0.0479, Validation Accuracy: 99.5314%\n",
      "Epoch 55/100, Loss: 0.0028\n",
      "Validation Loss: 0.0495, Validation Accuracy: 99.7188%\n",
      "Epoch 56/100, Loss: 0.0042\n",
      "Validation Loss: 0.0492, Validation Accuracy: 99.6251%\n",
      "Epoch 57/100, Loss: 0.0052\n",
      "Validation Loss: 0.0770, Validation Accuracy: 99.5314%\n",
      "Epoch 58/100, Loss: 0.0052\n",
      "Validation Loss: 0.0604, Validation Accuracy: 99.5314%\n",
      "Epoch 59/100, Loss: 0.0041\n",
      "Validation Loss: 0.0650, Validation Accuracy: 99.5314%\n",
      "Epoch 60/100, Loss: 0.0038\n",
      "Validation Loss: 0.0791, Validation Accuracy: 99.5314%\n",
      "Epoch 61/100, Loss: 0.0011\n",
      "Validation Loss: 0.0749, Validation Accuracy: 99.5314%\n",
      "Epoch 62/100, Loss: 0.0015\n",
      "Validation Loss: 0.0654, Validation Accuracy: 99.5314%\n",
      "Epoch 63/100, Loss: 0.0027\n",
      "Validation Loss: 0.0663, Validation Accuracy: 99.5314%\n",
      "Epoch 64/100, Loss: 0.0026\n",
      "Validation Loss: 0.0751, Validation Accuracy: 99.5314%\n",
      "Epoch 65/100, Loss: 0.0069\n",
      "Validation Loss: 0.0766, Validation Accuracy: 99.5314%\n",
      "Epoch 66/100, Loss: 0.0027\n",
      "Validation Loss: 0.0817, Validation Accuracy: 99.5314%\n",
      "Epoch 67/100, Loss: 0.0041\n",
      "Validation Loss: 0.0963, Validation Accuracy: 99.5314%\n",
      "Epoch 68/100, Loss: 0.0015\n",
      "Validation Loss: 0.0960, Validation Accuracy: 99.5314%\n",
      "Epoch 69/100, Loss: 0.0047\n",
      "Validation Loss: 0.0757, Validation Accuracy: 99.4377%\n",
      "Epoch 70/100, Loss: 0.0419\n",
      "Validation Loss: 0.1614, Validation Accuracy: 98.7816%\n",
      "Epoch 71/100, Loss: 0.0815\n",
      "Validation Loss: 0.0321, Validation Accuracy: 99.3440%\n",
      "Epoch 72/100, Loss: 0.0210\n",
      "Validation Loss: 0.0699, Validation Accuracy: 99.5314%\n",
      "Epoch 73/100, Loss: 0.0084\n",
      "Validation Loss: 0.0323, Validation Accuracy: 99.7188%\n",
      "Epoch 74/100, Loss: 0.0066\n",
      "Validation Loss: 0.0334, Validation Accuracy: 99.7188%\n",
      "Epoch 75/100, Loss: 0.0027\n",
      "Validation Loss: 0.0365, Validation Accuracy: 99.7188%\n",
      "Epoch 76/100, Loss: 0.0046\n",
      "Validation Loss: 0.0347, Validation Accuracy: 99.7188%\n",
      "Epoch 77/100, Loss: 0.0015\n",
      "Validation Loss: 0.0330, Validation Accuracy: 99.7188%\n",
      "Epoch 78/100, Loss: 0.0060\n",
      "Validation Loss: 0.0351, Validation Accuracy: 99.5314%\n",
      "Epoch 79/100, Loss: 0.0039\n",
      "Validation Loss: 0.0295, Validation Accuracy: 99.6251%\n",
      "Epoch 80/100, Loss: 0.0023\n",
      "Validation Loss: 0.0327, Validation Accuracy: 99.6251%\n",
      "Epoch 81/100, Loss: 0.0025\n",
      "Validation Loss: 0.0310, Validation Accuracy: 99.6251%\n",
      "Epoch 82/100, Loss: 0.0022\n",
      "Validation Loss: 0.0332, Validation Accuracy: 99.6251%\n",
      "Epoch 83/100, Loss: 0.0018\n",
      "Validation Loss: 0.0321, Validation Accuracy: 99.6251%\n",
      "Epoch 84/100, Loss: 0.0022\n",
      "Validation Loss: 0.0325, Validation Accuracy: 99.6251%\n",
      "Epoch 85/100, Loss: 0.0022\n",
      "Validation Loss: 0.0373, Validation Accuracy: 99.6251%\n",
      "Epoch 86/100, Loss: 0.0024\n",
      "Validation Loss: 0.0368, Validation Accuracy: 99.6251%\n",
      "Epoch 87/100, Loss: 0.0023\n",
      "Validation Loss: 0.0357, Validation Accuracy: 99.6251%\n",
      "Epoch 88/100, Loss: 0.0035\n",
      "Validation Loss: 0.0376, Validation Accuracy: 99.6251%\n",
      "Epoch 89/100, Loss: 0.0026\n",
      "Validation Loss: 0.0407, Validation Accuracy: 99.6251%\n",
      "Epoch 90/100, Loss: 0.0019\n",
      "Validation Loss: 0.0478, Validation Accuracy: 99.6251%\n",
      "Epoch 91/100, Loss: 0.0018\n",
      "Validation Loss: 0.0456, Validation Accuracy: 99.6251%\n",
      "Epoch 92/100, Loss: 0.0026\n",
      "Validation Loss: 0.0542, Validation Accuracy: 99.6251%\n",
      "Epoch 93/100, Loss: 0.0023\n",
      "Validation Loss: 0.0412, Validation Accuracy: 99.6251%\n",
      "Epoch 94/100, Loss: 0.0052\n",
      "Validation Loss: 0.0593, Validation Accuracy: 99.4377%\n",
      "Epoch 95/100, Loss: 0.0668\n",
      "Validation Loss: 0.0880, Validation Accuracy: 97.7507%\n",
      "Epoch 96/100, Loss: 0.0354\n",
      "Validation Loss: 0.0098, Validation Accuracy: 99.5314%\n",
      "Epoch 97/100, Loss: 0.0063\n",
      "Validation Loss: 0.0047, Validation Accuracy: 99.9063%\n",
      "Epoch 98/100, Loss: 0.0032\n",
      "Validation Loss: 0.0047, Validation Accuracy: 99.9063%\n",
      "Epoch 99/100, Loss: 0.0035\n",
      "Validation Loss: 0.0053, Validation Accuracy: 99.9063%\n",
      "Epoch 100/100, Loss: 0.0035\n",
      "Validation Loss: 0.0058, Validation Accuracy: 99.9063%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (mfcc, label) in enumerate(train_loader):\n",
    "        mfcc = mfcc.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mfcc)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * mfcc.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for mfcc, label in val_loader:\n",
    "            mfcc = mfcc.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(mfcc)\n",
    "            loss = criterion(output, label)\n",
    "            val_running_loss += loss.item() * mfcc.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_dataset)\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'audio_cnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y2/vgf9zr3956dc6krqf1hkc50m0000gn/T/ipykernel_5356/4198201259.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('audio_cnn_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AudioCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=8960, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNN(num_labels=num_labels, input_height=n_mfcc, input_width=max_length)\n",
    "model.load_state_dict(torch.load('audio_cnn_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inference samples: 2946\n",
      "Shape of one feature: (40, 115)\n"
     ]
    }
   ],
   "source": [
    "# Load inference features\n",
    "val_features = np.load('val_features.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Number of inference samples: {len(val_features)}\")\n",
    "print(f\"Shape of one feature: {val_features[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalization parameters\n",
    "mean = np.load('mean.npy')\n",
    "std = np.load('std.npy')\n",
    "\n",
    "def normalize(features, mean, std):\n",
    "    return (features - mean) / std\n",
    "\n",
    "# Normalize inference data\n",
    "val_features_norm = [normalize(f, mean, std) for f in val_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.X = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = self.X[idx]\n",
    "        mfcc = torch.tensor(mfcc, dtype=torch.float32)\n",
    "        mfcc = mfcc.unsqueeze(0)  # Shape: (1, n_mfcc, max_length)\n",
    "        return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 0, 7, 6, 3, 6, 3, 1, 2, 6, 1, 7, 0, 4, 0, 1, 7, 7, 6, 2, 1, 4, 7, 7, 7, 6, 5, 2, 1, 4, 0, 7, 2, 4, 2, 2, 6, 1, 2, 3, 5, 2, 7, 6, 2, 7, 3, 7, 2, 7, 7, 6, 2, 7, 2, 4, 4, 7, 6, 7, 7, 1, 7, 3, 3, 7, 4, 1, 7, 4, 6, 2, 1, 7, 7, 6, 7, 7, 1, 3, 7, 7, 2, 7, 6, 3, 0, 2, 7, 3, 6, 2, 6, 2, 2, 7, 7, 7, 2, 7, 6, 0, 7, 7, 2, 7, 7, 6, 7, 6, 7, 6, 3, 7, 4, 3, 6, 4, 5, 7, 7, 6, 1, 4, 7, 5, 6, 7, 5, 6, 4, 7, 7, 0, 7, 7, 7, 4, 0, 7, 5, 0, 7, 7, 5, 2, 0, 2, 2, 7, 0, 2, 4, 1, 4, 0, 7, 7, 7, 7, 2, 1, 7, 3, 1, 2, 6, 7, 7, 0, 6, 7, 3, 7, 7, 3, 6, 6, 1, 0, 7, 7, 1, 0, 4, 4, 4, 2, 2, 6, 6, 7, 6, 7, 7, 4, 6, 1, 0, 5, 6, 4, 7, 7, 4, 7, 2, 2, 0, 4, 4, 1, 4, 7, 6, 0, 1, 7, 6, 2, 2, 4, 7, 5, 7, 7, 6, 6, 3, 7, 2, 5, 2, 2, 1, 7, 4, 7, 1, 7, 1, 2, 3, 7, 6, 7, 4, 7, 3, 2, 0, 6, 0, 7, 6, 0, 7, 2, 7, 4, 2, 2, 7, 7, 6, 7, 6, 6, 4, 2, 2, 4, 6, 6, 0, 5, 7, 6, 6, 2, 6, 7, 7, 2, 7, 3, 3, 6, 3, 7, 7, 6, 7, 2, 7, 4, 6, 2, 2, 5, 5, 0, 2, 1, 6, 2, 2, 7, 0, 3, 5, 7, 7, 7, 6, 7, 7, 7, 7, 2, 3, 6, 1, 2, 6, 2, 3, 0, 4, 7, 7, 6, 1, 7, 1, 1, 5, 1, 5, 4, 7, 7, 7, 3, 4, 1, 6, 7, 4, 7, 7, 2, 2, 7, 2, 7, 7, 1, 7, 5, 4, 2, 2, 7, 6, 5, 3, 6, 7, 7, 2, 2, 1, 2, 4, 7, 1, 7, 6, 5, 6, 7, 1, 5, 3, 6, 2, 5, 3, 7, 6, 2, 7, 4, 2, 3, 3, 0, 2, 7, 7, 7, 2, 7, 7, 1, 1, 6, 7, 7, 7, 1, 2, 7, 2, 2, 1, 7, 6, 7, 5, 2, 3, 7, 4, 7, 7, 1, 3, 3, 7, 3, 6, 3, 2, 6, 7, 4, 1, 6, 2, 1, 5, 7, 3, 7, 2, 7, 3, 0, 7, 4, 4, 7, 6, 6, 2, 2, 3, 6, 3, 3, 6, 7, 1, 2, 7, 6, 7, 2, 0, 6, 6, 4, 0, 0, 7, 7, 7, 1, 6, 6, 2, 2, 2, 6, 1, 4, 2, 5, 7, 7, 6, 3, 6, 3, 7, 1, 0, 7, 4, 0, 2, 2, 1, 7, 0, 7, 6, 0, 3, 7, 2, 3, 6, 6, 2, 7, 7, 6, 7, 2, 2, 3, 7, 6, 6, 3, 7, 3, 7, 2, 6, 4, 4, 3, 5, 1, 4, 7, 2, 6, 7, 0, 7, 6, 7, 6, 6, 7, 6, 2, 0, 1, 6, 4, 6, 7, 6, 7, 7, 7, 2, 4, 7, 2, 1, 5, 7, 7, 3, 1, 5, 7, 7, 4, 2, 7, 6, 6, 7, 4, 7, 4, 0, 2, 4, 2, 7, 5, 5, 1, 6, 3, 7, 6, 1, 2, 6, 4, 6, 6, 0, 6, 7, 7, 2, 7, 7, 4, 7, 7, 0, 5, 5, 2, 6, 1, 2, 7, 5, 2, 2, 6, 5, 7, 4, 2, 7, 3, 7, 7, 2, 7, 7, 7, 1, 7, 2, 5, 4, 5, 2, 7, 7, 6, 2, 7, 7, 2, 1, 0, 2, 2, 4, 7, 1, 7, 4, 2, 2, 1, 2, 7, 0, 6, 0, 1, 0, 7, 0, 0, 2, 0, 5, 6, 2, 7, 0, 5, 7, 0, 2, 5, 1, 5, 6, 2, 6, 0, 5, 2, 5, 1, 7, 7, 2, 5, 3, 6, 5, 6, 3, 7, 5, 0, 2, 2, 6, 6, 7, 1, 6, 4, 1, 0, 6, 4, 3, 0, 4, 2, 7, 4, 0, 6, 5, 3, 5, 7, 6, 4, 0, 1, 4, 7, 1, 5, 2, 7, 6, 6, 4, 6, 2, 7, 2, 3, 7, 1, 1, 1, 4, 7, 5, 6, 0, 3, 4, 4, 2, 2, 7, 7, 2, 2, 5, 7, 6, 5, 5, 1, 4, 3, 1, 5, 0, 6, 5, 6, 1, 0, 2, 0, 2, 7, 6, 1, 5, 0, 1, 4, 4, 2, 6, 3, 5, 7, 1, 3, 7, 5, 2, 4, 7, 1, 0, 4, 1, 5, 4, 3, 2, 0, 7, 6, 6, 7, 3, 6, 5, 0, 3, 2, 4, 2, 2, 4, 6, 5, 6, 5, 1, 7, 4, 7, 1, 5, 2, 0, 2, 3, 2, 4, 6, 3, 4, 0, 0, 3, 6, 4, 3, 5, 5, 4, 3, 2, 7, 4, 2, 6, 4, 1, 5, 3, 4, 3, 2, 5, 1, 0, 2, 7, 3, 0, 4, 1, 3, 0, 4, 6, 0, 4, 6, 2, 1, 1, 2, 3, 0, 1, 6, 4, 6, 6, 7, 7, 2, 2, 6, 0, 3, 7, 5, 6, 1, 6, 3, 4, 3, 3, 0, 5, 7, 3, 6, 6, 1, 6, 4, 6, 6, 6, 4, 6, 2, 4, 1, 3, 5, 6, 3, 6, 3, 6, 5, 1, 3, 5, 5, 6, 5, 7, 7, 7, 1, 5, 1, 3, 1, 4, 7, 4, 7, 2, 7, 1, 3, 6, 5, 0, 6, 3, 1, 3, 2, 3, 5, 6, 7, 1, 0, 7, 5, 5, 0, 1, 1, 0, 1, 1, 2, 7, 1, 7, 7, 2, 4, 2, 1, 4, 5, 2, 3, 7, 0, 4, 7, 4, 6, 2, 2, 2, 0, 5, 7, 3, 5, 0, 0, 5, 4, 2, 7, 2, 3, 2, 3, 4, 4, 0, 0, 7, 6, 3, 5, 1, 3, 3, 4, 3, 5, 2, 5, 3, 3, 5, 6, 3, 4, 7, 1, 4, 7, 5, 2, 6, 7, 7, 6, 3, 7, 0, 6, 4, 4, 0, 7, 2, 1, 6, 5, 7, 6, 1, 1, 4, 4, 3, 1, 4, 4, 5, 4, 2, 7, 3, 5, 2, 2, 4, 3, 7, 4, 2, 0, 2, 6, 1, 2, 2, 2, 1, 0, 4, 0, 5, 0, 6, 4, 1, 2, 2, 4, 5, 5, 0, 6, 7, 5, 4, 1, 5, 3, 7, 4, 1, 4, 3, 7, 7, 6, 0, 3, 5, 3, 5, 1, 3, 6, 3, 5, 0, 0, 2, 1, 1, 5, 0, 5, 4, 2, 1, 2, 2, 3, 5, 7, 1, 5, 2, 4, 4, 7, 6, 5, 2, 7, 5, 5, 6, 6, 5, 6, 0, 6, 3, 7, 6, 7, 3, 0, 3, 3, 0, 1, 0, 5, 2, 3, 1, 0, 3, 4, 0, 5, 3, 7, 3, 0, 5, 6, 6, 3, 5, 7, 0, 2, 7, 2, 2, 5, 2, 0, 3, 0, 3, 0, 0, 1, 2, 1, 6, 0, 7, 0, 0, 5, 2, 5, 3, 7, 3, 4, 6, 1, 1, 7, 2, 1, 6, 0, 4, 4, 5, 5, 0, 0, 3, 5, 0, 7, 3, 1, 2, 6, 2, 7, 0, 6, 6, 1, 1, 3, 3, 6, 3, 5, 4, 0, 2, 1, 2, 0, 4, 5, 0, 2, 5, 5, 5, 0, 3, 5, 4, 1, 0, 1, 2, 0, 0, 4, 5, 7, 7, 0, 1, 2, 4, 7, 5, 2, 4, 7, 3, 7, 4, 4, 1, 6, 1, 2, 7, 5, 4, 2, 5, 2, 3, 4, 1, 1, 6, 3, 5, 6, 2, 3, 5, 3, 2, 3, 7, 2, 0, 1, 3, 4, 7, 1, 1, 3, 1, 3, 7, 4, 0, 1, 0, 6, 3, 7, 6, 5, 1, 6, 2, 7, 2, 5, 7, 3, 4, 7, 1, 7, 6, 2, 5, 5, 2, 1, 5, 3, 5, 4, 0, 5, 6, 0, 1, 7, 3, 6, 0, 1, 6, 0, 5, 6, 2, 0, 4, 5, 6, 3, 4, 2, 4, 1, 4, 6, 5, 6, 3, 2, 3, 3, 1, 2, 5, 1, 3, 6, 0, 2, 2, 1, 4, 4, 6, 6, 7, 7, 5, 4, 5, 4, 6, 2, 4, 4, 3, 2, 5, 4, 4, 7, 5, 6, 4, 4, 7, 4, 3, 2, 6, 7, 3, 7, 2, 3, 0, 2, 2, 7, 7, 3, 5, 7, 2, 5, 2, 5, 2, 1, 2, 2, 5, 0, 2, 4, 6, 0, 7, 5, 4, 3, 7, 2, 1, 3, 2, 5, 7, 2, 1, 6, 0, 2, 1, 5, 7, 3, 7, 4, 0, 3, 1, 2, 7, 2, 6, 0, 2, 1, 1, 1, 1, 3, 0, 4, 3, 7, 6, 5, 1, 2, 7, 7, 6, 5, 3, 7, 4, 6, 3, 0, 7, 4, 6, 3, 7, 3, 4, 4, 2, 6, 4, 0, 5, 3, 0, 2, 1, 2, 6, 1, 4, 2, 3, 2, 0, 6, 6, 7, 7, 4, 2, 1, 1, 3, 7, 4, 7, 2, 5, 3, 1, 7, 6, 0, 7, 0, 6, 4, 5, 0, 2, 6, 7, 0, 6, 5, 4, 5, 6, 0, 2, 1, 5, 0, 7, 3, 0, 6, 4, 7, 5, 1, 6, 3, 0, 2, 0, 1, 1, 2, 7, 4, 4, 0, 2, 1, 2, 7, 7, 3, 0, 5, 4, 5, 6, 2, 3, 4, 0, 2, 7, 3, 2, 4, 2, 6, 1, 2, 7, 2, 4, 4, 2, 4, 4, 6, 4, 3, 1, 3, 2, 1, 0, 2, 4, 3, 1, 3, 3, 6, 2, 2, 7, 2, 4, 0, 7, 2, 7, 7, 5, 5, 4, 2, 4, 0, 6, 2, 7, 2, 6, 6, 1, 3, 0, 6, 3, 3, 1, 1, 2, 3, 0, 3, 4, 1, 1, 6, 2, 6, 6, 1, 6, 2, 3, 2, 1, 0, 4, 1, 0, 1, 6, 2, 3, 5, 0, 6, 1, 5, 5, 4, 1, 6, 3, 0, 0, 2, 6, 6, 7, 1, 2, 7, 6, 1, 4, 1, 3, 0, 4, 3, 6, 3, 1, 2, 6, 2, 4, 3, 4, 7, 1, 5, 4, 0, 4, 1, 4, 0, 7, 4, 3, 0, 2, 2, 4, 0, 4, 6, 2, 0, 1, 0, 0, 2, 3, 1, 5, 7, 4, 7, 2, 5, 7, 5, 2, 3, 3, 6, 0, 3, 7, 3, 0, 4, 5, 1, 2, 7, 0, 2, 3, 6, 1, 2, 3, 5, 1, 3, 7, 5, 7, 2, 6, 2, 5, 3, 5, 3, 2, 0, 3, 0, 5, 6, 6, 1, 3, 2, 7, 4, 3, 3, 3, 4, 1, 7, 7, 0, 1, 0, 3, 3, 1, 7, 6, 4, 4, 3, 4, 5, 7, 2, 4, 3, 7, 2, 4, 2, 0, 3, 5, 2, 5, 4, 7, 0, 2, 4, 7, 4, 7, 4, 1, 3, 5, 2, 4, 3, 0, 1, 7, 3, 3, 5, 6, 1, 2, 1, 2, 2, 0, 6, 0, 4, 2, 3, 4, 5, 1, 0, 2, 6, 6, 2, 4, 1, 5, 2, 3, 4, 0, 3, 2, 2, 5, 6, 3, 5, 3, 6, 1, 0, 5, 4, 1, 0, 2, 1, 2, 3, 7, 5, 2, 2, 6, 4, 6, 1, 1, 7, 2, 0, 2, 0, 7, 5, 2, 7, 1, 4, 2, 5, 6, 2, 6, 7, 3, 0, 2, 1, 0, 6, 6, 5, 2, 1, 7, 4, 6, 3, 1, 3, 0, 6, 5, 1, 4, 5, 4, 2, 4, 4, 2, 1, 3, 6, 1, 4, 6, 6, 3, 5, 5, 5, 7, 3, 5, 0, 0, 3, 0, 1, 2, 3, 1, 3, 5, 4, 0, 7, 3, 6, 7, 1, 0, 3, 5, 5, 0, 1, 6, 3, 3, 0, 0, 4, 1, 7, 4, 4, 2, 2, 1, 7, 3, 2, 2, 5, 5, 1, 6, 5, 6, 5, 3, 2, 5, 2, 1, 3, 6, 1, 5, 6, 4, 3, 1, 4, 0, 1, 2, 3, 4, 1, 7, 1, 6, 7, 4, 5, 4, 0, 5, 2, 7, 1, 4, 2, 1, 0, 4, 6, 7, 4, 6, 1, 1, 0, 4, 5, 4, 5, 1, 4, 2, 2, 4, 0, 0, 7, 3, 4, 2, 2, 1, 5, 3, 3, 6, 3, 6, 1, 2, 1, 6, 3, 4, 0, 3, 7, 2, 2, 3, 7, 7, 1, 4, 0, 1, 6, 4, 5, 1, 1, 3, 1, 3, 7, 0, 5, 2, 1, 2, 5, 0, 0, 6, 7, 5, 2, 5, 5, 1, 7, 4, 4, 6, 3, 7, 6, 3, 6, 0, 1, 2, 2, 2, 4, 6, 4, 0, 1, 3, 7, 5, 4, 3, 2, 0, 5, 1, 4, 6, 4, 7, 2, 6, 0, 0, 2, 1, 3, 7, 6, 7, 6, 0, 6, 2, 3, 5, 1, 6, 5, 4, 0, 2, 7, 1, 0, 4, 2, 2, 7, 7, 3, 6, 6, 4, 5, 6, 2, 4, 0, 6, 6, 7, 6, 0, 7, 2, 5, 6, 3, 3, 6, 3, 3, 1, 2, 5, 4, 3, 4, 5, 0, 0, 5, 2, 2, 7, 5, 5, 6, 6, 2, 5, 1, 2, 6, 6, 5, 1, 2, 0, 1, 7, 5, 6, 7, 3, 4, 2, 4, 2, 5, 1, 7, 5, 1, 5, 3, 6, 1, 4, 7, 6, 3, 4, 1, 3, 5, 1, 2, 4, 7, 3, 6, 2, 6, 0, 4, 6, 5, 7, 2, 4, 7, 5, 2, 3, 3, 0, 4, 5, 5, 2, 4, 2, 2, 7, 3, 1, 0, 2, 1, 7, 4, 3, 1, 5, 7, 0, 4, 2, 5, 4, 3, 7, 6, 5, 0, 0, 1, 3, 0, 1, 1, 7, 7, 0, 3, 3, 2, 5, 7, 7, 4, 2, 2, 5, 1, 0, 6, 2, 5, 7, 3, 4, 1, 6, 3, 6, 5, 4, 1, 6, 1, 2, 5, 7, 3, 7, 2, 0, 2, 6, 4, 1, 2, 5, 6, 4, 1, 4, 0, 7, 0, 6, 5, 5, 1, 4, 7, 7, 6, 4, 6, 1, 3, 4, 5, 7, 5, 2, 0, 2, 6, 2, 3, 4, 1, 5, 3, 0, 5, 0, 5, 7, 1, 1, 4, 7, 0, 0, 6, 5, 2, 2, 7, 4, 0, 7, 3, 4, 2, 6, 4, 0, 2, 6, 6, 0, 3, 5, 3, 0, 4, 1, 7, 6, 6, 4, 3, 2, 7, 5, 3, 6, 6, 3, 7, 7, 0, 7, 7, 1, 2, 4, 5, 3, 6, 6, 2, 4, 7, 5, 2, 3, 7, 4, 3, 5, 0, 2, 6, 1, 2, 1, 3, 2, 4, 4, 3, 6, 1, 3, 0, 5, 4, 0, 0, 1, 2, 7, 4, 6, 4, 3, 5, 1, 0, 0, 0, 2, 5, 0, 1, 0, 6, 2, 1, 2, 5, 5, 0, 4, 0, 7, 7, 7, 3, 6, 1, 1, 1, 5, 5, 7, 7, 0, 7, 2, 7, 4, 1, 6, 3, 2, 0, 6, 6, 5, 6, 7, 5, 3, 2, 6, 2, 7, 1, 4, 4, 6, 5, 0, 3, 0, 3, 6, 6, 1, 5, 3, 0, 2, 1, 7, 2, 7, 2, 5, 2, 0, 1, 0, 2, 6, 5, 6, 1, 2, 5, 1, 3, 0, 7, 6, 7, 4, 1, 7, 7, 3, 0, 6, 2, 2, 5, 1, 6, 2, 5, 5, 6, 6, 5, 3, 4, 7, 0, 2, 5, 6, 3, 0, 6, 7, 1, 7, 1, 7, 0, 3, 0, 2, 6, 0, 7, 6, 2, 6, 2, 6, 2, 6, 1, 3, 4, 1, 3, 0, 7, 7, 5, 5, 7, 4, 6, 0, 6, 6, 2, 6, 7, 3, 0, 1, 0, 2, 5, 7, 1, 3, 5, 2, 1, 1, 4, 6, 7, 2, 6, 2, 4, 5, 3, 3, 1, 0, 1, 0, 1, 7, 1, 0, 1, 3, 7, 4, 3, 4, 5, 1, 7, 0, 6, 7, 1, 6, 0, 3, 7, 7, 1, 7, 5, 2, 0, 6, 7, 2, 0, 6, 0, 6, 5, 3, 2, 7, 5, 4, 4, 7, 0, 0, 0, 3, 4, 4, 2, 5, 4, 1, 4, 0, 2, 2, 5, 4, 2, 2, 4, 3, 2, 7, 2, 1, 0, 1, 0, 5, 5, 1, 7, 7, 3, 7, 7, 5, 6, 3, 0, 1, 0, 0, 7, 0, 0, 3, 5, 7, 5, 2, 7, 2, 1, 0, 1, 5, 1, 5, 3, 1, 6, 4, 3, 7, 0, 7, 0, 3, 3, 2, 6, 1, 7, 2, 0, 3, 3, 5, 3, 1, 6, 4, 6, 3, 6, 6, 1, 1, 4, 0, 5, 5, 2, 7, 0, 7, 0, 1, 4, 4, 1, 7, 7, 5, 4, 6, 0, 1, 3, 5, 6, 5, 2, 7, 2, 6, 1, 2, 2, 7, 7, 5, 4, 0, 0, 4, 2, 1, 7, 7, 3, 7, 1, 4, 1, 2, 5, 6, 6, 4, 0, 4, 6, 6, 3, 6, 5, 0, 4, 5, 1, 7, 2, 2, 4, 0, 1, 6, 1, 0, 0, 0, 4, 7, 4, 2, 4, 6, 2, 4, 3, 0, 5, 1, 4, 3, 5, 1, 3, 1, 1, 6, 4, 0, 2, 2, 3, 3, 3, 5, 6, 1, 0, 3, 7, 0, 4, 1, 7, 6, 0, 7, 0, 7, 2, 0, 0, 0, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create inference dataset\n",
    "inference_dataset = InferenceDataset(val_features_norm)\n",
    "\n",
    "# Create dataloader\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for mfcc in inference_loader:\n",
    "        mfcc = mfcc.to(device)\n",
    "        output = model(mfcc)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        all_predictions.extend(predicted.tolist())\n",
    "\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': 0, 'down': 1, 'go': 2, 'right': 3, 'up': 4, 'yes': 5, 'no': 6, 'stop': 7}\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv('../Train.csv')\n",
    "unique_classes = metadata_df['class'].unique()\n",
    "class_mapping = {class_name: idx for idx, class_name in enumerate(unique_classes)}\n",
    "\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_inverted = {v: k for k, v in class_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_names = [class_mapping_inverted[pred_id] for pred_id in all_predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_metadata = pd.read_csv('../Test_1.csv')\n",
    "ids = inference_metadata['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'class': predicted_class_names\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  class\n",
      "0  id_u5iqtgjzhx     no\n",
      "1  id_l7ebzcfk5e   left\n",
      "2  id_jbzci8uepl   stop\n",
      "3  id_jzil0fw5vs     no\n",
      "4  id_o7mrvf5wj7  right\n"
     ]
    }
   ],
   "source": [
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
